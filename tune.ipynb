{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "This is a notebook that shows you how to tune plankton ML models using the 'tune' class.\n",
    "\n",
    "This is the first notebook in a set of three:\n",
    "\n",
    "    - tune.ipynb: tune hyper-parameters to find the best model configuration\n",
    "\n",
    "    - predict.ipynb: make predictions using the best fitting model\n",
    "\n",
    "    - post.ipynb: analyse predictions and calculate metrics such as diversity\n",
    "\n",
    "There are several dependencies that need to be install prior to running this notebook:\n",
    "\n",
    "    pandas\n",
    "    numpy\n",
    "    scikit-learn\n",
    "    xgboost\n",
    "    joblib\n",
    "    \n",
    "\n",
    "Tuned models and scoring are saved using the following directory structure:\n",
    "\n",
    "    \n",
    "    /your_base_path/scoring/xgb/sppA_reg.sav\n",
    "    /your_base_path/scoring/rf/sppA_reg.sav\n",
    "    /your_base_path/scoring/rf/sppA_reg.sav\n",
    "\n",
    "    \n",
    "    /your_base_path/tuning/xgb/sppA_reg.sav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tune import tune \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from yaml import safe_load, load, dump\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf_scoring': {'accuracy': 'balanced_accuracy'}, 'reg_scoring': {'R2': 'r2', 'MAE': 'neg_mean_absolute_error', 'RMSE': 'neg_root_mean_squared_error'}, 'rf_param_grid': {'reg_param_grid': {'regressor__n_estimators': [100], 'regressor__max_features': [2, 3, 4], 'regressor__max_depth': [3, 5], 'regressor__min_samples_leaf': [0.2, 0.5, 0.8], 'regressor__max_samples': [0.2, 0.5, 0.8]}, 'clf_param_grid': {'n_estimators': [100], 'max_features': [2, 3, 4], 'max_depth': [3, 5], 'min_samples_leaf': [0.2, 0.5, 0.8], 'max_samples': [0.5]}}, 'xgb_param_grid': {'clf_param_grid': {'eta': [0.01], 'n_estimators': [10], 'max_depth': [4], 'subsample': [0.6], 'colsample_bytree': [0.6], 'gamma': [1], 'alpha': [1]}, 'reg_param_grid': {'regressor__eta': [0.01], 'regressor__n_estimators': [10], 'regressor__max_depth': [4], 'regressor__subsample': [0.6], 'regressor__colsample_bytree': [0.6], 'regressor__gamma': [1], 'regressor__alpha': [1]}}, 'knn_param_grid': {'clf_param_grid': {'max_samples': [0.5], 'max_features': [0.5], 'estimator__leaf_size': [30], 'estimator__n_neighbors': [3], 'estimator__p': [1], 'estimator__weights': ['uniform']}, 'reg_param_grid': {'regressor__max_samples': [0.5], 'regressor__max_features': [0.5], 'regressor__estimator__leaf_size': [30], 'regressor__estimator__n_neighbors': [3], 'regressor__estimator__p': [1], 'regressor__estimator__weights': ['uniform']}}}\n"
     ]
    }
   ],
   "source": [
    "# Setting up the model\n",
    "\n",
    "with open('/home/phyto/planktonSDM/model_config.yml', 'r') as f:\n",
    "    model_config = load(f, Loader=Loader)\n",
    "\n",
    "\n",
    "seed = 1 # random seed\n",
    "n_threads = 2 # how many cpu threads to use\n",
    "n_spp = 0 # which species to model\n",
    "path_out = \"/home/phyto/ModelOutput/test/\" #where to save model output\n",
    "\n",
    "\n",
    "X, y = make_regression(n_samples=500, n_features=5, noise=20, random_state=59)\n",
    "# scale so values are strictly positive:\n",
    "scaler = MinMaxScaler()  \n",
    "scaler.fit(y.reshape(-1,1))  \n",
    "y = scaler.transform(y.reshape(-1,1))\n",
    "# add exp transformation to data\n",
    "# make distribution exponential:\n",
    "y = np.exp(y)-1\n",
    "#cut tail\n",
    "y[y <= 0.5] = 0\n",
    "y = np.squeeze(y)\n",
    "\n",
    "#name y with species name\n",
    "\n",
    "cv = 3\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.24979607584108895\n",
      "reg rMAE: -0.24979607584108895\n",
      "reg R2: 0.3765433093248478\n",
      "execution time: 12.329315900802612 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-phase Random forest \n",
    "'''\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['rf_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"rf\", zir=False, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.24979607584108895\n",
      "reg rMAE: -0.24979607584108895\n",
      "reg R2: 0.3765433093248478\n",
      "zir rRMSE: -0.24979607584108895\n",
      "zir rMAE: -0.24979607584108895\n",
      "zir R2: 0.3765433093248478\n",
      "execution time: 16.189189434051514 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-phase Random forest \n",
    "note: for the 2-phase model we need to define the model configuration for both the classifier and the regressor\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "clf_scoring = model_config['clf_scoring']\n",
    "\n",
    "clf_param_grid = model_config['rf_param_grid']['clf_param_grid']\n",
    "reg_param_grid = model_config['rf_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, clf_scoring = clf_scoring, clf_param_grid = clf_param_grid, \n",
    "      cv=cv, model=\"rf\", zir=True, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.24817451463290974\n",
      "reg rMAE: -0.24817451463290974\n",
      "reg R2: 0.3845985809620281\n",
      "execution time: 22.195815086364746 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing the impact of log transformation on the 1-phase Random forest \n",
    "\n",
    "note: we test both log and no-log by defining log=\"both\"\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['rf_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"rf\", zir=False, log=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.6049248181787253\n",
      "reg rMAE: -0.6049248181787253\n",
      "reg R2: -2.6547241748838233\n",
      "execution time: 0.2293400764465332 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-phase Gradient boosting with XGBoost:\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['xgb_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"xgb\", zir=False, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.6065273458128824\n",
      "reg rMAE: -0.6065273458128824\n",
      "reg R2: 0.05456661376035166\n",
      "zir rRMSE: -0.5274685344635704\n",
      "zir rMAE: -0.5274685344635704\n",
      "zir R2: 0.2844541176880262\n",
      "execution time: 0.59261155128479 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-phase Gradient boosting with XGBoost:\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "clf_scoring = model_config['clf_scoring']\n",
    "\n",
    "clf_param_grid = model_config['xgb_param_grid']['clf_param_grid']\n",
    "reg_param_grid = model_config['xgb_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, clf_scoring = clf_scoring, clf_param_grid = clf_param_grid,\n",
    "      cv=cv, model=\"xgb\", zir=True, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.44664058917447036\n",
      "reg rMAE: -0.44664058917447036\n",
      "reg R2: 0.48736673651578083\n",
      "execution time: 0.5374126434326172 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-phase nearest neighbors with a bagged KNN\n",
    "note: we need to define the number of bags when running KNN by defining bagging_estimators=30\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['knn_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"knn\", zir=False, log=\"yes\", bagging_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: -0.48138705366221834\n",
      "reg rMAE: -0.48138705366221834\n",
      "reg R2: 0.4045149637539427\n",
      "zir rRMSE: -0.4574185755799064\n",
      "zir rMAE: -0.4574185755799064\n",
      "zir R2: 0.45665439310040346\n",
      "execution time: 1.6946873664855957 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-phase nearest neighbors with a bagged KNN\n",
    "note: we need to define the number of bags when running KNN by defining bagging_estimators=30\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "clf_scoring = model_config['clf_scoring']\n",
    "\n",
    "clf_param_grid = model_config['knn_param_grid']['clf_param_grid']\n",
    "reg_param_grid = model_config['knn_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid,  clf_scoring = clf_scoring, clf_param_grid = clf_param_grid,  \n",
    "      cv=cv, model=\"knn\", zir=True, log=\"both\", bagging_estimators=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "    \n",
    "Add print statement for log=\"both\"\n",
    "\n",
    "Add tau scoring\n",
    "\n",
    "Add one_hot_encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
