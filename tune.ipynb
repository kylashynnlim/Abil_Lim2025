{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "This is a notebook that shows you how to tune plankton ML models using the 'tune' class.\n",
    "\n",
    "This is the first notebook in a set of three:\n",
    "\n",
    "    - tune.ipynb: tune hyper-parameters to find the best model configuration\n",
    "\n",
    "    - predict.ipynb: make predictions using the best fitting model\n",
    "\n",
    "    - post.ipynb: analyse predictions and calculate metrics such as diversity\n",
    "\n",
    "There are several dependencies that need to be install prior to running this notebook:\n",
    "\n",
    "    pandas\n",
    "    numpy\n",
    "    scikit-learn\n",
    "    xgboost\n",
    "    joblib\n",
    "    \n",
    "\n",
    "Tuned models and scoring are saved using the following directory structure:\n",
    "\n",
    "    \n",
    "    /your_base_path/scoring/xgb/sppA_reg.sav\n",
    "    /your_base_path/scoring/rf/sppA_reg.sav\n",
    "    /your_base_path/scoring/rf/sppA_reg.sav\n",
    "\n",
    "    \n",
    "    /your_base_path/tuning/xgb/sppA_reg.sav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tune import tune \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from yaml import safe_load, load, dump\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "\n",
    "with open('/home/phyto/planktonSDM/model_config.yml', 'r') as f:\n",
    "    model_config = load(f, Loader=Loader)\n",
    "\n",
    "\n",
    "seed = 1 # random seed\n",
    "n_threads = 8 # how many cpu threads to use\n",
    "n_spp = 0 # which species to model\n",
    "path_out = \"/home/phyto/ModelOutput/test/\" #where to save model output\n",
    "\n",
    "\n",
    "X, y = make_regression(n_samples=500, n_features=5, noise=20, random_state=59)\n",
    "# scale so values are strictly positive:\n",
    "scaler = MinMaxScaler()  \n",
    "scaler.fit(y.reshape(-1,1))  \n",
    "y = scaler.transform(y.reshape(-1,1))\n",
    "# add exp transformation to data\n",
    "# make distribution exponential:\n",
    "y = np.exp(y)-1\n",
    "#cut tail\n",
    "y[y <= 0.5] = 0\n",
    "y = np.squeeze(y)\n",
    "\n",
    "#name y with species name\n",
    "\n",
    "cv = 3\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: 48%\n",
      "reg rMAE: 40.0%\n",
      "reg R2: 0.42\n",
      "execution time: 10.665565490722656 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-phase Random forest \n",
    "'''\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['rf_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"rf\", zir=False, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: 48%\n",
      "reg rMAE: 40.0%\n",
      "reg R2: 0.42\n",
      "zir rRMSE: 48.0\n",
      "zir rMAE: 39.0\n",
      "zir R2: 0.42\n",
      "execution time: 16.967652797698975 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-phase Random forest \n",
    "note: for the 2-phase model we need to define the model configuration for both the classifier and the regressor\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "clf_scoring = model_config['clf_scoring']\n",
    "\n",
    "clf_param_grid = model_config['rf_param_grid']['clf_param_grid']\n",
    "reg_param_grid = model_config['rf_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, clf_scoring = clf_scoring, clf_param_grid = clf_param_grid, \n",
    "      cv=cv, model=\"rf\", zir=True, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: 47%\n",
      "reg rMAE: 40.0%\n",
      "reg R2: 0.42\n",
      "execution time: 19.654861211776733 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing the impact of log transformation on the 1-phase Random forest \n",
    "\n",
    "note: we test both log and no-log by defining log=\"both\"\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['rf_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"rf\", zir=False, log=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "finished tuning model\n",
      "reg rRMSE: 61%\n",
      "reg rMAE: 50.0%\n",
      "reg R2: 0.05\n",
      "execution time: 0.6898267269134521 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-phase Gradient boosting with XGBoost:\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['xgb_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"xgb\", zir=False, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: 61%\n",
      "reg rMAE: 50.0%\n",
      "reg R2: 0.05\n",
      "zir rRMSE: 53.0\n",
      "zir rMAE: 37.0\n",
      "zir R2: 0.28\n",
      "execution time: 1.9003465175628662 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-phase Gradient boosting with XGBoost:\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "clf_scoring = model_config['clf_scoring']\n",
    "\n",
    "clf_param_grid = model_config['xgb_param_grid']['clf_param_grid']\n",
    "reg_param_grid = model_config['xgb_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, clf_scoring = clf_scoring, clf_param_grid = clf_param_grid,\n",
    "      cv=cv, model=\"xgb\", zir=True, log=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "finished tuning model\n",
      "reg rRMSE: 48%\n",
      "reg rMAE: 40.0%\n",
      "reg R2: 0.4\n",
      "execution time: 1.3744845390319824 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-phase nearest neighbors with a bagged KNN\n",
    "note: we need to define the number of bags when running KNN by defining bagging_estimators=30\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "reg_param_grid = model_config['knn_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid, cv=cv, model=\"knn\", zir=False, log=\"yes\", bagging_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend MultiprocessingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tuning model\n",
      "reg rRMSE: 40%\n",
      "reg rMAE: 30.0%\n",
      "reg R2: 0.58\n",
      "zir rRMSE: 43.0\n",
      "zir rMAE: 28.999999999999996\n",
      "zir R2: 0.53\n",
      "execution time: 4.422145128250122 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-phase nearest neighbors with a bagged KNN\n",
    "note: we need to define the number of bags when running KNN by defining bagging_estimators=30\n",
    "'''\n",
    "\n",
    "reg_scoring = model_config['reg_scoring']\n",
    "clf_scoring = model_config['clf_scoring']\n",
    "\n",
    "clf_param_grid = model_config['knn_param_grid']['clf_param_grid']\n",
    "reg_param_grid = model_config['knn_param_grid']['reg_param_grid']\n",
    "\n",
    "m = tune(X, y, seed, n_threads, verbose, cv, path_out)\n",
    "m.XGB(reg_scoring, reg_param_grid,  clf_scoring = clf_scoring, clf_param_grid = clf_param_grid,  \n",
    "      cv=cv, model=\"knn\", zir=True, log=\"both\", bagging_estimators=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "    \n",
    "Add print statement for log=\"both\"\n",
    "\n",
    "Add tau scoring\n",
    "\n",
    "Add one_hot_encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
